{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from data import gen_adult_probs\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wasserstein_fairness.wasserstein_fairness import combined_costs, basic_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = gen_adult_probs(interv='pre/in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.features = ad.features[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.protected_attributes = ad.protected_attributes[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.labels = ad.labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "lrm = LogisticRegression().fit(ad.features, ad.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JiangPenalizedLogReg():\n",
    "\n",
    "    def __init__(self, beta, alpha, num_iter, learning_rate):\n",
    "        self.beta = beta # TODO\n",
    "        self.alpha = alpha # TODO\n",
    "        self.lr = learning_rate\n",
    "        self.num_iter = num_iter\n",
    "        self.theta = None # model weights\n",
    "\n",
    "    def fit(self, X, y, sensvec, verbose=True):\n",
    "        \n",
    "        # calculate barycenter step....?\n",
    "        # initialize theta with output of LR\n",
    "        self.theta = LogisticRegression().fit(X, y).coef_\n",
    "\n",
    "        for i in range(self.num_iter):\n",
    "            shuffleinds = np.arange(len(X))\n",
    "            np.random.shuffle(shuffleinds)\n",
    "\n",
    "            currx = X[shuffleinds]\n",
    "            all_features = currx, y[shuffleinds]\n",
    "            prot_feats = []\n",
    "            for sens in [0,1]:\n",
    "                prot_feats.append(currx[sensvec.reshape(-1) == sens])\n",
    "\n",
    "            print(type(currx))\n",
    "            print(type(self.theta))\n",
    "            grad, reg_cost, wass_cost = combined_costs.gradient_line_logistic(all_features, \n",
    "                        prot_feats,theta=self.theta, beta=self.beta, alpha=self.alpha, \n",
    "                        distance='wasserstein-1')\n",
    "            \n",
    "            self.theta -= self.lr*grad\n",
    "\n",
    "            if verbose and i % 1000 == 0:\n",
    "                print(\"Round\", i, \", reg cost\", reg_cost, \"wass cost\", wass_cost)\n",
    "            \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return basic_costs.predict_prob(X, self.theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = JiangPenalizedLogReg(beta=1, alpha=0.5, num_iter=10, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5).reshape(1, -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16],\n",
       "       [17, 18, 19, 20]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 1 + np.arange(20).reshape(5,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  5, 18, 39, 68],\n",
       "       [ 0,  6, 20, 42, 72],\n",
       "       [ 0,  7, 22, 45, 76],\n",
       "       [ 0,  8, 24, 48, 80]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [18, 20, 22, 24],\n",
       "       [39, 42, 45, 48],\n",
       "       [68, 72, 76, 80]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b * a.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a * b.T - b * a.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "got data and ran model\n",
      "got basic gradients\n",
      "[0.32876712 0.6        1.         0.         0.43663912 0.39795918]\n",
      "getting coupling\n",
      "hello, log was {'cost': 0.00517647058823529}\n",
      "average of coupling 0.0\n",
      "sum of coupling 0\n",
      "(1000, 340)\n",
      "got coupling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (340,1000) (1000,340) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10572/126782995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotected_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10572/907464612.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sensvec, verbose)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             grad, reg_cost, wass_cost = combined_costs.gradient_line_logistic(all_features, \n\u001b[0m\u001b[1;32m     29\u001b[0m                         \u001b[0mprot_feats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                         distance='wasserstein-1')\n",
      "\u001b[0;32m/mnt/c/Users/jeska/work/wasserstein_fairness/wasserstein_fairness/combined_costs.py\u001b[0m in \u001b[0;36mgradient_line_logistic\u001b[0;34m(dataframes_all_data, dataframes_protected, theta, beta, alpha, distance, delta, baryscore)\u001b[0m\n\u001b[1;32m    137\u001b[0m         outputs_all_data, op)\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return _gradient_function_core(\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mdataframes_all_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframes_protected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_coupling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       beta, alpha, distance, delta, baryscore)\n",
      "\u001b[0;32m/mnt/c/Users/jeska/work/wasserstein_fairness/wasserstein_fairness/combined_costs.py\u001b[0m in \u001b[0;36m_gradient_function_core\u001b[0;34m(dataframes_all_data, dataframes_protected, theta, get_coupling, beta, alpha, distance, delta, baryscore)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m#       coupling * od.reshape((1, -1))).sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m           cost_wasserstein += abs(\n\u001b[0;32m--> 273\u001b[0;31m               \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcoupling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m               coupling * od.reshape((-1, 1))).sum()\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Compute the Wasserstein gradient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (340,1000) (1000,340) "
     ]
    }
   ],
   "source": [
    "test.fit(ad.features, ad.labels, ad.protected_attributes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c5b6e23e2039ba026f415e82c4b975cdb6bfdecf273cac0fd6224ba3f1d87c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
